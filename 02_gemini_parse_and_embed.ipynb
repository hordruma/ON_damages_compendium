{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ontario Damages Compendium Parser - Gemini Version\n",
    "\n",
    "This notebook demonstrates how to parse the Ontario Damages Compendium PDF using Google's Gemini API.\n",
    "\n",
    "## Features\n",
    "\n",
    "- Intelligent case parsing with Gemini 2.0 Flash\n",
    "- Multi-plaintiff support\n",
    "- Family Law Act claims extraction\n",
    "- Checkpoint/resume functionality\n",
    "- Automatic embedding generation\n",
    "- Dashboard-compatible output\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (if needed)\n",
    "# !pip install pdfplumber requests pandas sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the parser modules\n",
    "from damages_parser_gemini import (\n",
    "    parse_compendium,\n",
    "    DamagesCompendiumParser,\n",
    "    PDFTextExtractor,\n",
    "    flatten_cases_to_records\n",
    ")\n",
    "from gemini_data_transformer import (\n",
    "    add_embeddings_to_gemini_cases,\n",
    "    extract_gemini_statistics,\n",
    "    convert_gemini_to_dashboard_format\n",
    ")\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "API_KEY = \"YOUR_GEMINI_API_KEY_HERE\"  # ‚ö†Ô∏è Replace with your actual API key\n",
    "\n",
    "# PDF path (download from https://cdn.ymaws.com/www.ccla-abcc.ca/resource/resmgr/pp-civlit/2024damagescompendium.pdf)\n",
    "PDF_PATH = \"2024damagescompendium.pdf\"\n",
    "\n",
    "# Output paths\n",
    "GEMINI_JSON = \"damages_full.json\"  # Raw Gemini output\n",
    "DASHBOARD_JSON = \"data/damages_with_embeddings.json\"  # Dashboard-compatible format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the PDF (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "if not Path(PDF_PATH).exists():\n",
    "    print(\"Downloading PDF...\")\n",
    "    url = \"https://cdn.ymaws.com/www.ccla-abcc.ca/resource/resmgr/pp-civlit/2024damagescompendium.pdf\"\n",
    "    response = requests.get(url, timeout=120)\n",
    "    Path(PDF_PATH).write_bytes(response.content)\n",
    "    print(f\"Downloaded {len(response.content) / 1024 / 1024:.1f} MB\")\n",
    "else:\n",
    "    print(f\"PDF already exists: {PDF_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Parse (All Pages)\n",
    "\n",
    "**Estimated time:** 30-60 minutes  \n",
    "**Estimated cost:** $0.20-$0.50 with Gemini 2.0 Flash\n",
    "\n",
    "The parser saves checkpoints after each page. If API quota runs out or there's an error, use the resume cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse entire PDF (fresh start)\n",
    "# ‚ö†Ô∏è Only run this cell if you want to start from scratch!\n",
    "\n",
    "all_cases = parse_compendium(\n",
    "    PDF_PATH,\n",
    "    api_key=API_KEY,\n",
    "    output_json=GEMINI_JSON\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Parsed {len(all_cases)} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume After Interruption\n",
    "\n",
    "If the parser stopped (API quota, network error, etc.), run this cell to **resume from where it left off**.\n",
    "\n",
    "It automatically:\n",
    "- Reads the checkpoint file to find the last processed page\n",
    "- Goes back 1 page for safety (in case last page was incomplete)\n",
    "- Loads existing parsed cases\n",
    "- Skips duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESUME from checkpoint (run this if parsing was interrupted)\n",
    "\n",
    "all_cases = parse_compendium(\n",
    "    PDF_PATH,\n",
    "    api_key=API_KEY,\n",
    "    output_json=GEMINI_JSON,\n",
    "    resume=True  # <-- This resumes from checkpoint\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Total cases: {len(all_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check checkpoint status\n",
    "\n",
    "if Path(\"parsing_checkpoint.json\").exists():\n",
    "    with open(\"parsing_checkpoint.json\") as f:\n",
    "        checkpoint = json.load(f)\n",
    "    print(f\"Last checkpoint:\")\n",
    "    print(f\"  Page: {checkpoint.get('last_page')}\")\n",
    "    print(f\"  Cases: {checkpoint.get('total_cases')}\")\n",
    "    print(f\"  Time: {pd.to_datetime(checkpoint.get('timestamp'), unit='s')}\")\n",
    "else:\n",
    "    print(\"No checkpoint found - start fresh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings for Dashboard\n",
    "\n",
    "Convert Gemini-parsed cases to dashboard format with embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dashboard format and generate embeddings\n",
    "# This may take 5-10 minutes for full dataset\n",
    "\n",
    "dashboard_cases = add_embeddings_to_gemini_cases(\n",
    "    GEMINI_JSON,\n",
    "    DASHBOARD_JSON\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Created {len(dashboard_cases)} dashboard-ready cases\")\n",
    "print(f\"\\nüìÅ Saved to:\")\n",
    "print(f\"  - Raw Gemini: {GEMINI_JSON}\")\n",
    "print(f\"  - Dashboard: {DASHBOARD_JSON}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from JSON if already parsed\n",
    "with open(GEMINI_JSON, \"r\") as f:\n",
    "    cases = json.load(f)\n",
    "\n",
    "print(f\"Total cases: {len(cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract statistics\n",
    "stats = extract_gemini_statistics(cases)\n",
    "\n",
    "print(\"üìä Statistics:\")\n",
    "print(f\"  Total cases: {stats['total_cases']:,}\")\n",
    "print(f\"  Total plaintiffs: {stats['total_plaintiffs']:,}\")\n",
    "print(f\"  Multi-plaintiff cases: {stats['multi_plaintiff_count']:,}\")\n",
    "print(f\"  Family Law Act cases: {stats['family_law_act_count']:,}\")\n",
    "\n",
    "print(\"\\nüí∞ Damages statistics:\")\n",
    "print(f\"  Count: {stats['damages_stats']['count']:,}\")\n",
    "print(f\"  Mean: ${stats['damages_stats']['mean']:,.0f}\")\n",
    "print(f\"  Median: ${stats['damages_stats']['median']:,.0f}\")\n",
    "print(f\"  Min: ${stats['damages_stats']['min']:,.0f}\")\n",
    "print(f\"  Max: ${stats['damages_stats']['max']:,.0f}\")\n",
    "\n",
    "print(\"\\nüè• Top categories:\")\n",
    "for cat, count in list(stats['categories'].items())[:10]:\n",
    "    print(f\"  {cat}: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to DataFrame\n",
    "\n",
    "Flatten the nested structure for ML/analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten to DataFrame\n",
    "records = flatten_cases_to_records(cases)\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Non-pecuniary damages statistics:\")\n",
    "print(df['non_pecuniary_damages'].describe())\n",
    "\n",
    "print(\"\\nBy category (top 10):\")\n",
    "print(\n",
    "    df.groupby('category')['non_pecuniary_damages']\n",
    "    .agg(['count', 'mean', 'median'])\n",
    "    .sort_values('count', ascending=False)\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV for ML\n",
    "csv_path = \"damages_flattened.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Multi-Plaintiff Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cases with multiple plaintiffs\n",
    "multi_plaintiff_cases = [c for c in cases if len(c.get('plaintiffs', [])) > 1]\n",
    "\n",
    "print(f\"Found {len(multi_plaintiff_cases)} multi-plaintiff cases\\n\")\n",
    "\n",
    "if multi_plaintiff_cases:\n",
    "    example = multi_plaintiff_cases[0]\n",
    "    print(f\"Example: {example.get('case_name')}\")\n",
    "    print(f\"Year: {example.get('year')}\")\n",
    "    print(f\"Category: {example.get('category')}\")\n",
    "    print(f\"\\nPlaintiffs:\")\n",
    "    for p in example.get('plaintiffs', []):\n",
    "        damages = p.get('non_pecuniary_damages')\n",
    "        print(f\"  {p.get('plaintiff_id')}: {p.get('sex')} {p.get('age')} years - ${damages:,.2f}\" if damages else f\"  {p.get('plaintiff_id')}: {p.get('sex')} {p.get('age')} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Family Law Act Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cases with FLA claims\n",
    "fla_cases = [c for c in cases if c.get('family_law_act_claims')]\n",
    "\n",
    "print(f\"Found {len(fla_cases)} cases with Family Law Act claims\\n\")\n",
    "\n",
    "if fla_cases:\n",
    "    example = fla_cases[0]\n",
    "    print(f\"Example: {example.get('case_name')}\")\n",
    "    print(f\"\\nFLA Claims:\")\n",
    "    for claim in example.get('family_law_act_claims', []):\n",
    "        amt = claim.get('amount')\n",
    "        desc = claim.get('description')\n",
    "        print(f\"  {desc}: ${amt:,.2f}\" if amt else f\"  {desc}: amount not specified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dashboard Integration\n",
    "\n",
    "Verify that the dashboard can load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading dashboard format\n",
    "with open(DASHBOARD_JSON) as f:\n",
    "    dashboard_data = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Dashboard data loaded: {len(dashboard_data)} cases\")\n",
    "\n",
    "# Check format\n",
    "sample = dashboard_data[0]\n",
    "print(\"\\nSample case structure:\")\n",
    "print(f\"  case_name: {sample.get('case_name')}\")\n",
    "print(f\"  region: {sample.get('region')}\")\n",
    "print(f\"  year: {sample.get('year')}\")\n",
    "print(f\"  damages: {sample.get('damages')}\")\n",
    "print(f\"  embedding: {len(sample.get('embedding', []))} dimensions\")\n",
    "print(f\"  has gemini_data: {'gemini_data' in sample}\")\n",
    "\n",
    "if 'gemini_data' in sample:\n",
    "    gemini = sample['gemini_data']\n",
    "    print(f\"\\nGemini data:\")\n",
    "    print(f\"  plaintiff_id: {gemini.get('plaintiff_id')}\")\n",
    "    print(f\"  injuries: {len(gemini.get('injuries', []))} listed\")\n",
    "    print(f\"  citations: {len(gemini.get('citations', []))} listed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Estimation\n",
    "\n",
    "Gemini 2.0 Flash pricing:\n",
    "- Input: $0.075 per 1M tokens\n",
    "- Output: $0.30 per 1M tokens\n",
    "\n",
    "For 655 pages:\n",
    "- ~500 tokens input per page\n",
    "- ~1000 tokens output per page\n",
    "- Total: ~325K input + ~650K output\n",
    "- **Estimated cost: ~$0.22**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rough cost estimate\n",
    "num_pages = 655\n",
    "input_tokens = num_pages * 500\n",
    "output_tokens = num_pages * 1000\n",
    "\n",
    "# Gemini 2.0 Flash pricing\n",
    "input_cost = (input_tokens / 1_000_000) * 0.075\n",
    "output_cost = (output_tokens / 1_000_000) * 0.30\n",
    "\n",
    "print(f\"Estimated tokens: {input_tokens:,} input, {output_tokens:,} output\")\n",
    "print(f\"Estimated cost: ${input_cost + output_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Run the dashboard**: `streamlit run streamlit_app.py`\n",
    "2. **Test search**: The dashboard will automatically detect and use the Gemini data\n",
    "3. **Verify**: Check that multi-plaintiff and FLA data displays correctly\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### API Errors\n",
    "- Check your API key is valid\n",
    "- Gemini has rate limits - the parser includes delays and retries\n",
    "- Use the resume functionality if interrupted\n",
    "\n",
    "### Missing Data\n",
    "- Some pages may not parse correctly\n",
    "- Check the `errors` list on the parser\n",
    "- Re-run specific pages if needed\n",
    "\n",
    "### Validation\n",
    "- Compare output against known cases\n",
    "- Spot-check multi-plaintiff cases manually\n",
    "- Verify FLA claims are accurate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
