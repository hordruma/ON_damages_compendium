{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser Debugging Notebook\n",
    "\n",
    "This notebook helps debug how the damages compendium PDF is being parsed.\n",
    "\n",
    "**What to look for:**\n",
    "- Section headers (Forearm, Spine, etc.) that become the `category` field\n",
    "- Whether the `region` field should come from somewhere else\n",
    "- What gets sent to the LLM for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Configuration\n",
    "PDF_PATH = \"2024damagescompendium.pdf\"\n",
    "SAMPLE_PAGES = [10, 20, 30, 50, 75, 100, 150, 200, 250, 300]  # 10 sample pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Extract Tables from Sample Pages\n",
    "\n",
    "We'll use both STREAM (for section headers) and LATTICE (for table structure) modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_info(pdf_path, page_num):\n",
    "    \"\"\"\n",
    "    Extract table information from a single page using both modes.\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'stream_tables', 'lattice_tables', and 'section_header'\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'page': page_num,\n",
    "        'stream_tables': [],\n",
    "        'lattice_tables': [],\n",
    "        'section_header': None\n",
    "    }\n",
    "    \n",
    "    # Extract with STREAM mode (captures section headers)\n",
    "    try:\n",
    "        stream_tables = camelot.read_pdf(\n",
    "            pdf_path,\n",
    "            pages=str(page_num),\n",
    "            flavor='stream',\n",
    "            edge_tol=50\n",
    "        )\n",
    "        \n",
    "        if stream_tables:\n",
    "            for table in stream_tables:\n",
    "                df = table.df\n",
    "                result['stream_tables'].append(df)\n",
    "                \n",
    "                # Check first row for section header\n",
    "                if len(df) > 0:\n",
    "                    first_row = ' '.join(str(x) for x in df.iloc[0].values if str(x).strip())\n",
    "                    # Common section headers: Forearm, Spine, Head, etc.\n",
    "                    if len(first_row) < 50 and not any(kw in first_row.lower() for kw in ['case', 'damages', 'age']):\n",
    "                        result['section_header'] = first_row.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Stream extraction error on page {page_num}: {e}\")\n",
    "    \n",
    "    # Extract with LATTICE mode (better table structure)\n",
    "    try:\n",
    "        lattice_tables = camelot.read_pdf(\n",
    "            pdf_path,\n",
    "            pages=str(page_num),\n",
    "            flavor='lattice'\n",
    "        )\n",
    "        \n",
    "        if lattice_tables:\n",
    "            for table in lattice_tables:\n",
    "                df = table.df\n",
    "                result['lattice_tables'].append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Lattice extraction error on page {page_num}: {e}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Extract all sample pages\n",
    "print(f\"Extracting tables from {len(SAMPLE_PAGES)} sample pages...\\n\")\n",
    "page_data = {}\n",
    "\n",
    "for page_num in SAMPLE_PAGES:\n",
    "    print(f\"Processing page {page_num}...\")\n",
    "    page_data[page_num] = extract_page_info(PDF_PATH, page_num)\n",
    "    \n",
    "print(f\"\\nâœ… Extracted data from {len(page_data)} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Display Section Headers Found\n",
    "\n",
    "These become the `category` field in the parsed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Section Headers Found:\\n\" + \"=\"*50)\n",
    "\n",
    "for page_num in SAMPLE_PAGES:\n",
    "    info = page_data[page_num]\n",
    "    section = info.get('section_header', 'None')\n",
    "    print(f\"Page {page_num:3d}: {section}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: View Sample Table Structure\n",
    "\n",
    "Let's look at what the actual table data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a page with a section header\n",
    "sample_page = None\n",
    "for page_num in SAMPLE_PAGES:\n",
    "    if page_data[page_num].get('section_header'):\n",
    "        sample_page = page_num\n",
    "        break\n",
    "\n",
    "if sample_page:\n",
    "    info = page_data[sample_page]\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"SAMPLE PAGE {sample_page}\")\n",
    "    print(f\"Section Header: {info['section_header']}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Show STREAM table\n",
    "    if info['stream_tables']:\n",
    "        print(\"\\n--- STREAM Mode (shows section headers) ---\")\n",
    "        display(info['stream_tables'][0].head(10))\n",
    "    \n",
    "    # Show LATTICE table\n",
    "    if info['lattice_tables']:\n",
    "        print(\"\\n--- LATTICE Mode (cleaner structure) ---\")\n",
    "        display(info['lattice_tables'][0].head(10))\n",
    "else:\n",
    "    print(\"No pages with section headers found in sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Simulate What Gets Sent to the LLM\n",
    "\n",
    "This shows exactly what the parser sends to the LLM for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_llm_prompt(section, columns, row_data):\n",
    "    \"\"\"\n",
    "    Recreate the exact prompt sent to the LLM.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Parse this table row from a legal damages compendium.\n",
    "\n",
    "Body Region/Category: {section}\n",
    "Table Columns: {columns}\n",
    "Row Data: {row_data}\n",
    "\n",
    "Extract the following information and return as JSON:\n",
    "{{\n",
    "  \"case_name\": \"Full case name (plaintiff v. defendant)\" or null,\n",
    "  \"plaintiff_name\": \"Plaintiff name only\" or null,\n",
    "  \"defendant_name\": \"Defendant name only\" or null,\n",
    "  \"year\": year as integer or null,\n",
    "  \"citation\": \"Citation string\" or null,\n",
    "  \"court\": \"Court name\" or null,\n",
    "  \"judge\": \"Judge's LAST NAME ONLY (e.g., 'Smith' not 'A. Smith J.'). For appeals with multiple judges, use a list like ['Smith', 'Jones', 'Brown']\" or null,\n",
    "  \"sex\": \"M\" or \"F\" or null,\n",
    "  \"age\": age as integer or null,\n",
    "  \"non_pecuniary_damages\": amount in dollars (number, no $ or commas) or null,\n",
    "  \"is_provisional\": true/false or null,\n",
    "  \"injuries\": [\"injury1\", \"injury2\"] or [],\n",
    "  \"other_damages\": [{{\"type\": \"future_loss_of_income|past_loss_of_income|cost_of_future_care|housekeeping_capacity|other\", \"amount\": number, \"description\": \"text\"}}] or [],\n",
    "  \"comments\": \"Additional notes\" or null,\n",
    "  \"is_continuation\": true if this row lacks case_name/citation (continuation of previous case), false otherwise\n",
    "}}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Show sample prompts\n",
    "if sample_page and info['lattice_tables']:\n",
    "    df = info['lattice_tables'][0]\n",
    "    section = info['section_header'] or 'UNKNOWN'\n",
    "    \n",
    "    # Get column names from first row\n",
    "    if len(df) > 1:\n",
    "        columns = list(df.iloc[0].values)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"SAMPLE LLM PROMPTS FOR PAGE {sample_page}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Show prompts for first 3 data rows\n",
    "        for i in range(1, min(4, len(df))):\n",
    "            row_data = list(df.iloc[i].values)\n",
    "            prompt = simulate_llm_prompt(section, columns, row_data)\n",
    "            \n",
    "            print(f\"\\n--- ROW {i} PROMPT ---\")\n",
    "            print(prompt[:800] + \"...\\n\" if len(prompt) > 800 else prompt)\n",
    "            print(f\"\\nNote: The section '{section}' is saved as 'category' field, NOT 'region' field!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Check Actual Parsed Data\n",
    "\n",
    "Compare with what's actually in damages_full.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parsed data\n",
    "with open('damages_full.json', 'r') as f:\n",
    "    parsed_cases = json.load(f)\n",
    "\n",
    "print(f\"\\nTotal parsed cases: {len(parsed_cases)}\\n\")\n",
    "\n",
    "# Analyze region vs category\n",
    "cases_with_region = sum(1 for c in parsed_cases if c.get('region'))\n",
    "cases_with_category = sum(1 for c in parsed_cases if c.get('category'))\n",
    "\n",
    "print(f\"Cases with 'region' field:   {cases_with_region:4d} ({cases_with_region/len(parsed_cases)*100:.1f}%)\")\n",
    "print(f\"Cases with 'category' field: {cases_with_category:4d} ({cases_with_category/len(parsed_cases)*100:.1f}%)\")\n",
    "\n",
    "# Sample cases\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE PARSED CASES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, case in enumerate(parsed_cases[:5]):\n",
    "    print(f\"\\nCase {i+1}: {case.get('case_name', 'Unknown')}\")\n",
    "    print(f\"  Category: {case.get('category', 'N/A')}\")\n",
    "    print(f\"  Region:   {case.get('region', 'N/A')}\")\n",
    "    print(f\"  Pages:    {case.get('source_pages', [])[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Diagnosis\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "1. The parser extracts section headers (e.g., \"Forearm\", \"Spine\") from the PDF\n",
    "2. These section headers are sent to the LLM as `Body Region/Category: {section}`\n",
    "3. The parsed data saves this as the `category` field\n",
    "4. The `region` field is a SEPARATE field that appears to come from somewhere else\n",
    "\n",
    "**Possible Issues:**\n",
    "\n",
    "- The `region` field might be from a different data source (manual annotations?)\n",
    "- The parser may need to be updated to ALSO save the section as `region`\n",
    "- Or the dashboard should use `category` instead of expecting `region`\n",
    "\n",
    "**Recommendation:**\n",
    "\n",
    "Since the section header IS being captured and sent to the LLM, we should either:\n",
    "1. Update the parser to save section as BOTH `category` AND `region`\n",
    "2. Update the dashboard to use `category` when `region` is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Suggested Fix\n",
    "\n",
    "Add this to the parser (around line 469 in damages_parser_table.py):\n",
    "\n",
    "```python\n",
    "data['source_page'] = page_number\n",
    "data['category'] = section\n",
    "data['region'] = [section]  # ADD THIS LINE - save section as region too\n",
    "```\n",
    "\n",
    "This would ensure both fields are populated with the anatomical section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
