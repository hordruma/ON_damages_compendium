{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Improvements - UX & FLA Normalization\n",
    "\n",
    "This notebook tests the following improvements:\n",
    "1. FLA cap removal\n",
    "2. FLA relationship normalization (fixes encoding errors, excludes general/punitive damages)\n",
    "3. Case summary label removal\n",
    "4. UX improvements (better sizing, color contrast)\n",
    "\n",
    "Run these tests before committing the PR to ensure all functionality works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Optional, List, Dict, Any\n",
    "import pandas as pd\n",
    "\n",
    "# Import the normalization function\n",
    "import sys\n",
    "sys.path.append('app/ui')\n",
    "from fla_analytics import normalize_fla_relationship, extract_fla_awards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: FLA Relationship Normalization\n",
    "\n",
    "Test that relationships are properly extracted and encoded errors are fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cases for relationship normalization\n",
    "test_cases = [\n",
    "    # (input, expected_output)\n",
    "    (\"€50,000 to spouse\", \"Spouse\"),\n",
    "    (\"Spouse - loss of guidance\", \"Spouse\"),\n",
    "    (\"Wife's claim\", \"Spouse\"),\n",
    "    (\"Husband\", \"Spouse\"),\n",
    "    (\"Child - loss of care\", \"Child\"),\n",
    "    (\"Son's claim\", \"Child\"),\n",
    "    (\"Daughter\", \"Child\"),\n",
    "    (\"Mother's claim\", \"Parent\"),\n",
    "    (\"Father - loss of companionship\", \"Parent\"),\n",
    "    (\"Brother's claim\", \"Sibling\"),\n",
    "    (\"Sister\", \"Sibling\"),\n",
    "    (\"Grandmother's claim\", \"Grandparent\"),\n",
    "    (\"Grandfather\", \"Grandparent\"),\n",
    "    (\"General damages\", None),  # Should be excluded\n",
    "    (\"Punitive damages\", None),  # Should be excluded\n",
    "    (\"Aggravated damages\", None),  # Should be excluded\n",
    "    (\"Special damages\", None),  # Should be excluded\n",
    "    (\"Costs\", None),  # Should be excluded\n",
    "    (\"â€ spouse claim\", \"Spouse\"),  # Encoding error fix\n",
    "    (\"€ child\", \"Child\"),  # Euro sign removal\n",
    "]\n",
    "\n",
    "print(\"Testing FLA Relationship Normalization\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "passed = 0\n",
    "failed = 0\n",
    "\n",
    "for input_desc, expected in test_cases:\n",
    "    result = normalize_fla_relationship(input_desc)\n",
    "    \n",
    "    if result == expected:\n",
    "        status = \"✓\"\n",
    "        passed += 1\n",
    "    else:\n",
    "        status = \"✗\"\n",
    "        failed += 1\n",
    "    \n",
    "    print(f\"{status} '{input_desc:40}' -> '{result}' (expected: '{expected}')\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Results: {passed} passed, {failed} failed\")\n",
    "\n",
    "if failed == 0:\n",
    "    print(\"\\n✅ All FLA normalization tests passed!\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ {failed} test(s) failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: FLA Awards Extraction\n",
    "\n",
    "Test that FLA awards are correctly extracted with normalized relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample case data\n",
    "sample_case = {\n",
    "    'case_name': 'Test v. Case',\n",
    "    'year': 2023,\n",
    "    'court': 'ONSC',\n",
    "    'extended_data': {\n",
    "        'family_law_act_claims': [\n",
    "            {\n",
    "                'description': '€50,000 - Spouse loss of guidance',\n",
    "                'amount': 50000,\n",
    "                'category': 'FLA'\n",
    "            },\n",
    "            {\n",
    "                'description': 'Child - loss of care and companionship',\n",
    "                'amount': 30000,\n",
    "                'category': 'FLA'\n",
    "            },\n",
    "            {\n",
    "                'description': 'General damages',\n",
    "                'amount': 100000,\n",
    "                'category': 'General'\n",
    "            },\n",
    "            {\n",
    "                'description': 'Punitive damages',\n",
    "                'amount': 25000,\n",
    "                'category': 'Punitive'\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "awards = extract_fla_awards(sample_case)\n",
    "\n",
    "print(\"Testing FLA Awards Extraction\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total claims in case: {len(sample_case['extended_data']['family_law_act_claims'])}\")\n",
    "print(f\"Valid FLA relationship claims: {len(awards)}\")\n",
    "print()\n",
    "\n",
    "for i, award in enumerate(awards, 1):\n",
    "    print(f\"Award {i}:\")\n",
    "    print(f\"  Normalized: {award['description']}\")\n",
    "    print(f\"  Original: {award['original_description']}\")\n",
    "    print(f\"  Amount: ${award['amount']:,}\")\n",
    "    print()\n",
    "\n",
    "print(\"Expected behavior:\")\n",
    "print(\"  - Should extract 2 awards (Spouse and Child)\")\n",
    "print(\"  - Should exclude 'General damages' and 'Punitive damages'\")\n",
    "print(\"  - Should normalize 'Spouse' and 'Child' relationships\")\n",
    "print(\"  - Should fix encoding errors (€ symbols removed)\")\n",
    "print()\n",
    "\n",
    "if len(awards) == 2:\n",
    "    print(\"✅ Extraction test passed!\")\n",
    "else:\n",
    "    print(f\"⚠️ Expected 2 awards, got {len(awards)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Load Real Data and Check Distribution\n",
    "\n",
    "Test on actual compendium data to see the impact of normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load actual data\n",
    "try:\n",
    "    with open('data/damages_with_embeddings.json', 'r') as f:\n",
    "        cases = json.load(f)\n",
    "    print(f\"Loaded {len(cases)} cases\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"Trying alternative path...\")\n",
    "    try:\n",
    "        with open('damages_full.json', 'r') as f:\n",
    "            cases = json.load(f)\n",
    "        print(f\"Loaded {len(cases)} cases from damages_full.json\")\n",
    "    except:\n",
    "        print(\"Could not load any data file\")\n",
    "        cases = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all FLA claims\n",
    "from collections import Counter\n",
    "\n",
    "all_awards = []\n",
    "excluded_count = 0\n",
    "original_descriptions = []\n",
    "normalized_relationships = []\n",
    "\n",
    "for case in cases:\n",
    "    extended_data = case.get('extended_data', {})\n",
    "    fla_claims = extended_data.get('family_law_act_claims', [])\n",
    "    \n",
    "    for claim in fla_claims:\n",
    "        desc = claim.get('description', '')\n",
    "        amount = claim.get('amount', 0)\n",
    "        \n",
    "        original_descriptions.append(desc)\n",
    "        \n",
    "        normalized = normalize_fla_relationship(desc)\n",
    "        \n",
    "        if normalized:\n",
    "            normalized_relationships.append(normalized)\n",
    "            if amount > 0:\n",
    "                all_awards.append(amount)\n",
    "        else:\n",
    "            excluded_count += 1\n",
    "\n",
    "print(\"FLA Claims Analysis\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total FLA claims found: {len(original_descriptions)}\")\n",
    "print(f\"Valid relationship claims: {len(normalized_relationships)}\")\n",
    "print(f\"Excluded (general/punitive/costs): {excluded_count}\")\n",
    "print()\n",
    "\n",
    "if normalized_relationships:\n",
    "    relationship_counts = Counter(normalized_relationships)\n",
    "    \n",
    "    print(\"Normalized Relationship Distribution:\")\n",
    "    for relationship, count in relationship_counts.most_common():\n",
    "        print(f\"  {relationship:20} : {count:4} ({count/len(normalized_relationships)*100:.1f}%)\")\n",
    "    print()\n",
    "\n",
    "if all_awards:\n",
    "    import numpy as np\n",
    "    print(\"Award Statistics (Valid FLA Relationships Only):\")\n",
    "    print(f\"  Count: {len(all_awards)}\")\n",
    "    print(f\"  Min: ${min(all_awards):,}\")\n",
    "    print(f\"  Median: ${np.median(all_awards):,.0f}\")\n",
    "    print(f\"  Max: ${max(all_awards):,}\")\n",
    "    print()\n",
    "\n",
    "print(\"✅ Data analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Encoding Error Detection\n",
    "\n",
    "Find and display cases with encoding errors that are being fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find encoding errors\n",
    "encoding_errors = []\n",
    "\n",
    "for desc in original_descriptions:\n",
    "    if desc and ('€' in desc or 'â' in desc):\n",
    "        normalized = normalize_fla_relationship(desc)\n",
    "        encoding_errors.append({\n",
    "            'original': desc,\n",
    "            'normalized': normalized\n",
    "        })\n",
    "\n",
    "print(\"Encoding Error Fixes\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Found {len(encoding_errors)} descriptions with encoding errors\")\n",
    "print()\n",
    "\n",
    "if encoding_errors:\n",
    "    print(\"Sample fixes (first 10):\")\n",
    "    for i, error in enumerate(encoding_errors[:10], 1):\n",
    "        print(f\"{i}. Original:   '{error['original']}'\")\n",
    "        print(f\"   Normalized: '{error['normalized']}'\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"✅ All encoding errors are being fixed!\")\n",
    "else:\n",
    "    print(\"No encoding errors found in current dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: Verify FLA Cap Removal\n",
    "\n",
    "Verify that FLA cap references are removed from the analytics module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the fla_analytics.py file for cap references\n",
    "import os\n",
    "\n",
    "fla_file_path = 'app/ui/fla_analytics.py'\n",
    "\n",
    "if os.path.exists(fla_file_path):\n",
    "    with open(fla_file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Check for cap-related keywords\n",
    "    cap_keywords = ['FLA_DAMAGES_CAP', 'fla_cap', 'create_fla_cap_chart']\n",
    "    found_caps = []\n",
    "    \n",
    "    for keyword in cap_keywords:\n",
    "        if keyword in content:\n",
    "            found_caps.append(keyword)\n",
    "    \n",
    "    print(\"FLA Cap Reference Check\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if found_caps:\n",
    "        print(f\"⚠️ Found {len(found_caps)} cap-related references:\")\n",
    "        for keyword in found_caps:\n",
    "            print(f\"  - {keyword}\")\n",
    "    else:\n",
    "        print(\"✅ No FLA cap references found - cap has been successfully removed!\")\n",
    "    \n",
    "    # Check for new distribution chart\n",
    "    if 'create_fla_distribution_chart' in content:\n",
    "        print(\"✅ New distribution chart function found\")\n",
    "    else:\n",
    "        print(\"⚠️ Distribution chart function not found\")\n",
    "else:\n",
    "    print(f\"File not found: {fla_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 6: Case Summary Display\n",
    "\n",
    "Verify that the \"Case Summary:\" label is removed from search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check streamlit_app.py for case summary label\n",
    "streamlit_file_path = 'streamlit_app.py'\n",
    "\n",
    "if os.path.exists(streamlit_file_path):\n",
    "    with open(streamlit_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Find case summary related lines\n",
    "    summary_lines = []\n",
    "    for i, line in enumerate(lines, 1):\n",
    "        if 'Case Summary' in line or 'summary_text' in line:\n",
    "            summary_lines.append((i, line.strip()))\n",
    "    \n",
    "    print(\"Case Summary Display Check\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    has_label = any('\"**Case Summary:**\"' in line or \"'**Case Summary:**'\" in line \n",
    "                    for _, line in summary_lines)\n",
    "    \n",
    "    if has_label:\n",
    "        print(\"⚠️ Found 'Case Summary:' label in code\")\n",
    "    else:\n",
    "        print(\"✅ 'Case Summary:' label has been removed!\")\n",
    "    \n",
    "    print(f\"\\nFound {len(summary_lines)} lines related to summary display:\")\n",
    "    for line_num, line in summary_lines[:5]:  # Show first 5\n",
    "        print(f\"  Line {line_num}: {line[:80]}\")\n",
    "else:\n",
    "    print(f\"File not found: {streamlit_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 7: CSS Improvements\n",
    "\n",
    "Verify that CSS has been updated for better contrast and sizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CSS improvements in streamlit_app.py\n",
    "if os.path.exists(streamlit_file_path):\n",
    "    with open(streamlit_file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Extract CSS block\n",
    "    import re\n",
    "    css_match = re.search(r'st\\.markdown\\(\"\"\"\\s*<style>(.*?)</style>', content, re.DOTALL)\n",
    "    \n",
    "    if css_match:\n",
    "        css_content = css_match.group(1)\n",
    "        \n",
    "        print(\"CSS Improvements Check\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Check for improved properties\n",
    "        improvements = [\n",
    "            ('Better font sizes', 'font-size: 1.05rem' in css_content or 'font-size: 1.1rem' in css_content),\n",
    "            ('Line height for readability', 'line-height: 1.6' in css_content or 'line-height: 1.7' in css_content),\n",
    "            ('Improved color contrast', '#111827' in css_content or '#1f2937' in css_content),\n",
    "            ('Better padding/spacing', 'padding: 1.25rem' in css_content or 'padding: 1.35rem' in css_content),\n",
    "            ('Expander improvements', 'expanderHeader' in css_content),\n",
    "            ('Metric improvements', 'stMetricValue' in css_content),\n",
    "        ]\n",
    "        \n",
    "        passed_improvements = sum(1 for _, check in improvements if check)\n",
    "        \n",
    "        for improvement, check in improvements:\n",
    "            status = \"✅\" if check else \"❌\"\n",
    "            print(f\"{status} {improvement}\")\n",
    "        \n",
    "        print()\n",
    "        print(f\"UX Improvements: {passed_improvements}/{len(improvements)} implemented\")\n",
    "        \n",
    "        if passed_improvements >= len(improvements) - 1:  # Allow 1 variation\n",
    "            print(\"\\n✅ CSS improvements successfully applied!\")\n",
    "        else:\n",
    "            print(f\"\\n⚠️ Only {passed_improvements} improvements found\")\n",
    "    else:\n",
    "        print(\"Could not find CSS block in streamlit_app.py\")\n",
    "else:\n",
    "    print(f\"File not found: {streamlit_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Run all cells above to verify:\n",
    "\n",
    "1. ✅ FLA relationship normalization works correctly\n",
    "2. ✅ Encoding errors (€ symbols) are fixed\n",
    "3. ✅ General/punitive damages are excluded\n",
    "4. ✅ FLA cap references are removed\n",
    "5. ✅ Distribution chart replaces cap chart\n",
    "6. ✅ \"Case Summary:\" label is removed\n",
    "7. ✅ CSS improvements for better UX\n",
    "\n",
    "All tests should pass before merging the PR!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
