#!/usr/bin/env python3
"""
Regenerate embeddings from damages_table_based.json with complete FLA data.

This script:
1. Loads damages_table_based.json (the authoritative source with all data)
2. Converts to dashboard format using data_transformer (preserving FLA claims)
3. Generates embeddings using sentence-transformers
4. Saves to data/damages_with_embeddings.json

This ensures all data (injuries, FLA claims, comments, etc.) is preserved.
"""

import json
from pathlib import Path
from sentence_transformers import SentenceTransformer
from data_transformer import convert_to_dashboard_format

def main():
    print("=" * 70)
    print("REGENERATING DAMAGES COMPENDIUM WITH COMPLETE DATA")
    print("=" * 70)

    # Load source data
    source_file = "damages_table_based.json"
    print(f"\nğŸ“‚ Loading source data from {source_file}...")

    with open(source_file, 'r', encoding='utf-8') as f:
        source_cases = json.load(f)

    print(f"   âœ“ Loaded {len(source_cases):,} cases")

    # Check FLA coverage in source
    fla_cases = [c for c in source_cases if c.get('family_law_act_claims')]
    fla_count = sum(len(c.get('family_law_act_claims', [])) for c in fla_cases)
    print(f"   âœ“ Source has {len(fla_cases)} cases with {fla_count} FLA claims")

    # Load embedding model
    print(f"\nğŸ”„ Loading embedding model (all-mpnet-base-v2)...")
    model = SentenceTransformer("sentence-transformers/all-mpnet-base-v2")
    print(f"   âœ“ Model loaded")

    # Convert to dashboard format
    print(f"\nğŸ”„ Converting to dashboard format...")
    print(f"   This preserves: injuries, FLA claims, comments, demographics")
    dashboard_cases = convert_to_dashboard_format(source_cases, model)
    print(f"   âœ“ Converted {len(dashboard_cases):,} cases")

    # Verify FLA preservation
    fla_dashboard = [c for c in dashboard_cases
                     if c.get('extended_data', {}).get('family_law_act_claims')]
    fla_dashboard_count = sum(
        len(c.get('extended_data', {}).get('family_law_act_claims', []))
        for c in fla_dashboard
    )
    print(f"   âœ“ Dashboard has {len(fla_dashboard)} cases with {fla_dashboard_count} FLA claims")

    if fla_dashboard_count != fla_count:
        print(f"   âš ï¸  WARNING: FLA count mismatch! Source: {fla_count}, Dashboard: {fla_dashboard_count}")
    else:
        print(f"   âœ… FLA claims successfully preserved!")

    # Verify injury preservation
    injury_cases = [c for c in dashboard_cases
                    if c.get('extended_data', {}).get('injuries')]
    print(f"   âœ“ Dashboard has {len(injury_cases)} cases with injuries")

    # Save to dashboard JSON
    output_path = Path("data/damages_with_embeddings.json")
    output_path.parent.mkdir(parents=True, exist_ok=True)

    print(f"\nğŸ’¾ Saving to {output_path}...")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(dashboard_cases, f, indent=2, ensure_ascii=False)

    size_mb = output_path.stat().st_size / 1024 / 1024
    print(f"   âœ“ Saved {size_mb:.1f} MB")

    # Summary
    print(f"\n" + "=" * 70)
    print(f"âœ… REGENERATION COMPLETE")
    print(f"=" * 70)
    print(f"\nğŸ“Š Summary:")
    print(f"   â€¢ Total cases: {len(dashboard_cases):,}")
    print(f"   â€¢ Cases with injuries: {len(injury_cases):,}")
    print(f"   â€¢ Cases with FLA claims: {len(fla_dashboard):,}")
    print(f"   â€¢ Total FLA relationships: {fla_dashboard_count:,}")
    print(f"\nğŸ“ Output: {output_path}")
    print(f"\nğŸ’¡ Next steps:")
    print(f"   1. Run generate_embeddings.py to create injury embeddings")
    print(f"   2. Restart Streamlit app to load new data")
    print()

if __name__ == "__main__":
    main()
