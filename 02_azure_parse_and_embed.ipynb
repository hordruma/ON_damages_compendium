{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ontario Damages Compendium Parser - Azure AI Foundry\n",
    "\n",
    "Parse the Ontario Damages Compendium PDF using Azure AI Foundry (OpenAI or Claude models).\n",
    "\n",
    "**Features:**\n",
    "- Supports Azure OpenAI (GPT-4o, GPT-4) and Claude models\n",
    "- Checkpoint/resume support for handling API quota limits\n",
    "- Multi-plaintiff and Family Law Act claims extraction\n",
    "- Automatic embedding generation for dashboard\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (if needed)\n",
    "# !pip install pdfplumber requests pandas sentence-transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from damages_parser_azure import parse_compendium, DamagesCompendiumParser\nfrom data_transformer import (\n    add_embeddings_to_cases,\n    extract_statistics\n)\nimport json\nimport pandas as pd\nfrom pathlib import Path"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Azure AI Foundry\n",
    "\n",
    "Fill in your Azure details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Azure OpenAI Configuration\nENDPOINT = \"https://your-resource.openai.azure.com/\"  # Replace with your Azure endpoint\nAPI_KEY = \"your-azure-api-key-here\"  # Replace with your API key\nMODEL = \"gpt-5-chat\"  # Your deployment name: gpt-5-chat or gpt-4o\n\nPDF_PATH = \"2024damagescompendium.pdf\"\nOUTPUT_JSON = \"damages_full.json\"\nDASHBOARD_JSON = \"data/damages_with_embeddings.json\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download PDF (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "if not Path(PDF_PATH).exists():\n",
    "    print(\"Downloading PDF...\")\n",
    "    url = \"https://cdn.ymaws.com/www.ccla-abcc.ca/resource/resmgr/pp-civlit/2024damagescompendium.pdf\"\n",
    "    response = requests.get(url, timeout=120)\n",
    "    Path(PDF_PATH).write_bytes(response.content)\n",
    "    print(f\"Downloaded {len(response.content) / 1024 / 1024:.1f} MB\")\n",
    "else:\n",
    "    print(f\"PDF already exists: {PDF_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Current Progress\n",
    "\n",
    "See if you have any existing progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check checkpoint from previous run\n",
    "if Path(\"parsing_checkpoint.json\").exists():\n",
    "    with open(\"parsing_checkpoint.json\") as f:\n",
    "        checkpoint = json.load(f)\n",
    "    print(f\"Checkpoint found:\")\n",
    "    print(f\"  Last page: {checkpoint.get('last_page_processed')}\")\n",
    "    print(f\"  Cases so far: {checkpoint.get('cases_count')}\")\n",
    "    print(f\"  Timestamp: {pd.to_datetime(checkpoint.get('timestamp'), unit='s')}\")\n",
    "else:\n",
    "    print(\"No checkpoint found\")\n",
    "\n",
    "# Check existing cases\n",
    "if Path(OUTPUT_JSON).exists():\n",
    "    with open(OUTPUT_JSON) as f:\n",
    "        existing = json.load(f)\n",
    "    print(f\"\\nExisting cases file: {len(existing)} cases\")\n",
    "else:\n",
    "    print(f\"\\nNo existing cases file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse PDF - Fresh Start\n",
    "\n",
    "‚ö†Ô∏è **Run this cell to start parsing from the beginning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start fresh\n",
    "cases = parse_compendium(\n",
    "    PDF_PATH,\n",
    "    endpoint=ENDPOINT,\n",
    "    api_key=API_KEY,\n",
    "    model=MODEL,\n",
    "    output_json=OUTPUT_JSON,\n",
    "    resume=False\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Parsed {len(cases)} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume from Checkpoint\n",
    "\n",
    "If parsing was interrupted, run this cell to continue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume from checkpoint\n",
    "cases = parse_compendium(\n",
    "    PDF_PATH,\n",
    "    endpoint=ENDPOINT,\n",
    "    api_key=API_KEY,\n",
    "    model=MODEL,\n",
    "    output_json=OUTPUT_JSON,\n",
    "    resume=True  # <-- Resume from last checkpoint\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Total cases: {len(cases)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Specific Page Range\n",
    "\n",
    "Useful for testing or parsing specific sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse specific page range\n",
    "cases = parse_compendium(\n",
    "    PDF_PATH,\n",
    "    endpoint=ENDPOINT,\n",
    "    api_key=API_KEY,\n",
    "    model=MODEL,\n",
    "    output_json=OUTPUT_JSON,\n",
    "    start_page=588,  # Start here\n",
    "    end_page=591     # Stop here\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Parsed pages 588-591: {len(cases)} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings for Dashboard\n",
    "\n",
    "Convert parsed cases to dashboard format with embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Convert to dashboard format and generate embeddings\n# This may take 5-10 minutes for full dataset\n\ndashboard_cases = add_embeddings_to_cases(\n    OUTPUT_JSON,\n    DASHBOARD_JSON\n)\n\nprint(f\"\\n‚úÖ Created {len(dashboard_cases)} dashboard-ready cases\")\nprint(f\"\\nüìÅ Saved to:\")\nprint(f\"  - Raw Azure: {OUTPUT_JSON}\")\nprint(f\"  - Dashboard: {DASHBOARD_JSON}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load all cases\nwith open(OUTPUT_JSON) as f:\n    cases = json.load(f)\n\nstats = extract_statistics(cases)\n\nprint(f\"üìä Statistics:\")\nprint(f\"  Total cases: {stats['total_cases']:,}\")\nprint(f\"  Total plaintiffs: {stats['total_plaintiffs']:,}\")\nprint(f\"  Multi-plaintiff cases: {stats['multi_plaintiff_count']:,}\")\nprint(f\"  Family Law Act cases: {stats['family_law_act_count']:,}\")\n\nprint(\"\\nüí∞ Damages statistics:\")\nprint(f\"  Count: {stats['damages_stats']['count']:,}\")\nprint(f\"  Mean: ${stats['damages_stats']['mean']:,.0f}\")\nprint(f\"  Median: ${stats['damages_stats']['median']:,.0f}\")\nprint(f\"  Min: ${stats['damages_stats']['min']:,.0f}\")\nprint(f\"  Max: ${stats['damages_stats']['max']:,.0f}\")\n\nprint(\"\\nüè• Top categories:\")\nfor cat, count in list(stats['categories'].items())[:10]:\n    print(f\"  {cat}: {count:,}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sample case\n",
    "if cases:\n",
    "    print(\"Sample case (most recent):\")\n",
    "    print(json.dumps(cases[-1], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_cases(cases):\n",
    "    \"\"\"Flatten nested case data to one row per plaintiff\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for case in cases:\n",
    "        base = {\n",
    "            'case_id': case.get('case_id'),\n",
    "            'case_name': case.get('case_name'),\n",
    "            'plaintiff_name': case.get('plaintiff_name'),\n",
    "            'defendant_name': case.get('defendant_name'),\n",
    "            'year': case.get('year'),\n",
    "            'category': case.get('category'),\n",
    "            'court': case.get('court'),\n",
    "            'source_page': case.get('source_page'),\n",
    "            'num_plaintiffs': len(case.get('plaintiffs', [])),\n",
    "            'has_fla_claims': bool(case.get('family_law_act_claims')),\n",
    "        }\n",
    "        \n",
    "        plaintiffs = case.get('plaintiffs', [])\n",
    "        if not plaintiffs:\n",
    "            rows.append(base)\n",
    "        else:\n",
    "            for p in plaintiffs:\n",
    "                row = base.copy()\n",
    "                row.update({\n",
    "                    'plaintiff_id': p.get('plaintiff_id'),\n",
    "                    'sex': p.get('sex'),\n",
    "                    'age': p.get('age'),\n",
    "                    'non_pecuniary_damages': p.get('non_pecuniary_damages'),\n",
    "                    'is_provisional': p.get('is_provisional'),\n",
    "                    'injuries': ', '.join(p.get('injuries', [])),\n",
    "                })\n",
    "                rows.append(row)\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df = flatten_cases(cases)\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df.to_csv(\"damages_flattened.csv\", index=False)\n",
    "print(\"Saved to damages_flattened.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats by category\n",
    "print(\"Non-pecuniary damages by category:\")\n",
    "print(\n",
    "    df.groupby('category')['non_pecuniary_damages']\n",
    "    .agg(['count', 'mean', 'median'])\n",
    "    .sort_values('count', ascending=False)\n",
    "    .head(15)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dashboard Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dashboard can load the data\n",
    "with open(DASHBOARD_JSON) as f:\n",
    "    dashboard_data = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Dashboard data loaded: {len(dashboard_data)} cases\")\n",
    "\n",
    "# Check format\n",
    "sample = dashboard_data[0]\n",
    "print(\"\\nSample case structure:\")\n",
    "print(f\"  case_name: {sample.get('case_name')}\")\n",
    "print(f\"  region: {sample.get('region')}\")\n",
    "print(f\"  year: {sample.get('year')}\")\n",
    "print(f\"  damages: {sample.get('damages')}\")\n",
    "print(f\"  embedding: {len(sample.get('embedding', []))} dimensions\")\n",
    "print(f\"  has gemini_data: {'gemini_data' in sample}\")\n",
    "\n",
    "if 'gemini_data' in sample:\n",
    "    gemini = sample['gemini_data']\n",
    "    print(f\"\\nExtended data:\")\n",
    "    print(f\"  source_page: {gemini.get('source_page')}\")\n",
    "    print(f\"  plaintiff_id: {gemini.get('plaintiff_id')}\")\n",
    "    print(f\"  injuries: {len(gemini.get('injuries', []))} listed\")\n",
    "    print(f\"  citations: {len(gemini.get('citations', []))} listed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<cell_type>markdown</cell_type>## Next Steps\n\n1. **Run the dashboard**: `streamlit run streamlit_app.py`\n2. **Test search**: The dashboard will automatically load your Azure-parsed data\n3. **Verify**: Check that all enhanced features display correctly\n\n## Cost Estimation\n\n### Azure OpenAI (GPT-5)\n- Input: ~$2.50 per 1M tokens\n- Output: ~$10 per 1M tokens\n- **Full PDF (655 pages)**: ~$4-6\n\n### Azure OpenAI (GPT-4o)\n- Input: ~$2.50 per 1M tokens\n- Output: ~$10 per 1M tokens\n- **Full PDF (655 pages)**: ~$4-6\n\n## Troubleshooting\n\n### API Errors\n- Verify your endpoint URL is correct\n- Check that your API key is valid\n- Ensure the deployment name matches your Azure deployment\n\n### Rate Limits\n- The parser includes automatic retry with exponential backoff\n- Use `resume=True` to continue after quota limits\n\n### Model Not Found\n- Check deployment name in Azure portal\n- Verify the model is deployed and available (gpt-5-chat or gpt-4o)\n- Ensure your deployment is active and not paused"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}